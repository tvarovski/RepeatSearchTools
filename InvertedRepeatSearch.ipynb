{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InvertedRepeatSearch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "o-CucBNksmES"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import regex as re\n",
        "import json\n",
        "\n",
        "def extractSeqFromFileToList(file_path):\n",
        "  '''This function takes a path of a fastafile and extracts all sequence names and\n",
        "  sequences into a nested list [[title_0, sequence_0], [title_1, sequence_1],...]'''\n",
        "\n",
        "  fasta_file = open(file_path, 'r')\n",
        "  contents = fasta_file.readlines()\n",
        "  fasta_file.close()\n",
        "\n",
        "  fasta_list=[]\n",
        "\n",
        "  for i in contents:\n",
        "    if '>' in i:\n",
        "      fasta_list.append([i.strip('>').strip(),''])\n",
        "    else:\n",
        "      fasta_list[-1][1] = fasta_list[-1][1]+i.strip()\n",
        "  print(f\"Extraction of sequence information from {file_path} finished.\")\n",
        "  return fasta_list\n",
        "\n",
        "\n",
        "def validateDNASquence(sequence):\n",
        "  '''Check if the sequence contains viable nucleotides only'''\n",
        "\n",
        "  bases = \"ATGCatgc-\"\n",
        "  for i in sequence:\n",
        "    if i not in bases:\n",
        "      print(\"warning, sequence doesn't contain cannonical nucleotides\")\n",
        "      return(False)\n",
        "  return(True)\n",
        "\n",
        "\n",
        "def compl(base):\n",
        "  if base == \"A\":\n",
        "    return('T')\n",
        "  elif base == \"T\":\n",
        "    return('A')\n",
        "  elif base == \"G\":\n",
        "    return('C')\n",
        "  elif base == \"C\":\n",
        "    return('G')\n",
        "  elif base == \"-\":\n",
        "    return('-')\n",
        "\n",
        "def rev_compl(seq):\n",
        "  new_seq = \"\"\n",
        "  for base in seq:\n",
        "    new_base = compl(base)\n",
        "    new_seq = new_base + new_seq\n",
        "  return(new_seq)\n",
        "\n",
        "def imperfectHomologySearch(sequence, query, min_homology=0.8, fixed_errors=False):\n",
        "\n",
        "  \n",
        "  if min_homology:\n",
        "    errors = round(len(query)*(1-min_homology))\n",
        "  if fixed_errors:\n",
        "    errors = fixed_errors\n",
        "  #print(f\"searching with {errors} errors...\")\n",
        "\n",
        "  output_list = re.findall( '(' + query + '){e<=' + str(errors) + '}', sequence)\n",
        "  \n",
        "  query_match_pairs=[rev_compl(query), output_list]\n",
        "  if len(output_list) > 0:\n",
        "    if len(output_list) > 1:\n",
        "      print(\"This is unusual...\")\n",
        "    print(f'Found possible template(s) for {rev_compl(query)}: {output_list}')\n",
        "    return(query_match_pairs)\n",
        "  else:\n",
        "    return([])\n",
        "\n",
        "\n",
        "def findInvertedRepeat(sequence, query_length=4, min_spacer=4, imperfect_homology=False, min_homology=0.8, fixed_errors=False):\n",
        "\n",
        "  query=sequence[:query_length]\n",
        "  sequence=sequence[query_length+min_spacer:]\n",
        "  query_complement = rev_compl(query)\n",
        "  output_pair_list=[]\n",
        "\n",
        "  for i in range(len(sequence)-query_length+1):\n",
        "    #print(sequence[i:query_length+i])\n",
        "    if imperfect_homology:\n",
        "      \n",
        "      output_pair=imperfectHomologySearch(sequence[i:query_length+i], query_complement, min_homology=min_homology,fixed_errors=fixed_errors)\n",
        "\n",
        "      if output_pair != []:\n",
        "        output_pair_list.append(output_pair)\n",
        "\n",
        "    else:\n",
        "      if sequence[i:query_length+i] == query_complement:\n",
        "        print(f\"Success, {sequence[i:query_length+i]}\")\n",
        "        output_pair_list.append([query, [sequence[i:query_length+i]]])\n",
        "\n",
        "  return(output_pair_list)\n",
        "    \n",
        "  \n",
        "def searchSequenceForRepeats(sequence, min_query_length=4, max_query_length=25, min_spacer=0, window_size=250, imperfect_homology=False, min_homology=0.8, fixed_errors=False):\n",
        "  \n",
        "  if imperfect_homology:\n",
        "    print(f\"Search has been set to find quasi-pallindromes\")\n",
        "    if fixed_errors:\n",
        "      print(f\"    Allowing up to {fixed_errors} errors/mismatches...\")\n",
        "    if not fixed_errors:\n",
        "      print(f\"    Searching with a minimum of {min_homology} homology\")\n",
        "  if not imperfect_homology:\n",
        "    print(f\"Search has been set to find perfect pallindromes\")\n",
        "\n",
        "  \n",
        "  list_of_all_pairs=[]\n",
        "  for query_length in range(min_query_length, max_query_length):\n",
        "    print(f\"###Searching for inverted-repeating {query_length}bp-long fragments...\")\n",
        "    sequence_size=len(sequence)\n",
        "    for i in range(sequence_size-window_size+1):\n",
        "      seq=sequence[i:i+window_size]\n",
        "      output_pair_list = findInvertedRepeat(seq, query_length=query_length, min_spacer=min_spacer, imperfect_homology=imperfect_homology, min_homology=min_homology, fixed_errors=fixed_errors)\n",
        "      for pair in output_pair_list:\n",
        "        list_of_all_pairs.append(pair)\n",
        "\n",
        "  results_dictionary={}\n",
        "  print(\"Consolodating Results...\")\n",
        "  for pair in list_of_all_pairs:\n",
        "    query=pair[0]\n",
        "    if query in results_dictionary:\n",
        "      if pair[1][0] not in results_dictionary[query]:\n",
        "        results_dictionary[query].append(pair[1][0])\n",
        "    else:\n",
        "      results_dictionary[query] = [pair[1][0]]\n",
        "  print(\"Results were consolidated...\")\n",
        "  return(results_dictionary)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload a sequence"
      ],
      "metadata": {
        "id": "UvZNGpgAfbAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Directly set the string\n",
        "sequence='ATGTCCACAAAATCATATACCAGTAGAGCTGAGACTCATGCAAGTCCGGTTGCATCGAAACTTTTACGTTTAATGGATGAAAAGAAGACCAATTTGTGTGCTTCTCTTGACGTTCGTTCGACTGATGAGCTATTGAAACTTGTTGAAACGTTGGGTCCATACATTTGCCTTTTGAAAACACACGTTGATATCTTGGATGATTTCAGTTATGAGGGTACTGTCGTTCCATTGAAAGCATTGGCAGAGAAATACAAGTTCTTGATATTTGAGGACAGAAAATTCGCCGATATCGGTAACACAGTCAAATTACAATATACATCGGGCGTTTACCGTATCGCAGAATGGTCTGATATCACCAACGCCCACGGGGTTACTGGTGCTGGTATTGTTGCTGGCTTGAAACAAGGTGCGCAAGAGGTCACCAAAGAACCAAGGGGATTATTGATGCTTGCTGAATTGTCTTCCAAGGGTTCTCTAGCACACGGTGAATATACTAAGGGTACCGTTGATATTGCAAAGAGTGATAAAGATTTCGTTATTGGGTTCATTGCTCAGAACGATATGGGAGGAAGAGAAGAAGGGTTTGATTGGCTAATCATGACCCCAGGTGTAGGTTTAGACGACAAAGGCGATGCATTGGGTCAGCAGTACAGAACCGTCGACGAAGTTGTAAGTGGTGGATCAGATATCATCATTGTTGGCAGAGGACTTTTCGCCAAGGGTAGAGATCCTAAGGTTGAAGGTGAAAGATACAGAAATGCTGGATGGGAAGCGTACCAAAAGAGAATCAGCGCTCCCCATTAA'\n",
        "\n",
        "#Or set file path\n",
        "#fasta_list=extractSeqFromFileToList(\"/content/Lys2.fa\")\n",
        "#sequence = fasta_list[0][1]\n",
        "\n",
        "#validate sequence\n",
        "\n",
        "print(f\"The uploaded sequence has {len(sequence)}bp\")\n",
        "if validateDNASquence(sequence):\n",
        "  print(\"### Sequence validated ###\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SWixitifd-d",
        "outputId": "c5891949-4813-4190-d20a-4db2263fedea"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The uploaded sequence has 804bp\n",
            "### Sequence validated ###\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Set repeat Search Parameters\n",
        "\n",
        "\n",
        "min_query_length=5        # Sets min length of a query sequence\n",
        "max_query_length=30       # Sets max length of a query sequence\n",
        "min_spacer=0              # Set min distance between query and the repeat\n",
        "window_size=700           # Sets window size within which the search is confined\n",
        "imperfect_homology=True   # Set True/False, to search for imperfect/perfect homologies.\n",
        "min_homology=0.9          # Sets minimum homology treshold (a fraction) when imperfect_homology=True,  \n",
        "fixed_errors=1            # Sets maximum number of errors (del/sub) when imperfect_homology=True (set to False or to an integer)\n",
        "\n",
        "#Run the search\n",
        "results_dictionary = searchSequenceForRepeats(sequence=sequence,\n",
        "                         min_query_length=min_query_length,\n",
        "                         max_query_length=max_query_length,\n",
        "                         min_spacer=min_spacer,\n",
        "                         window_size=window_size,\n",
        "                         imperfect_homology=imperfect_homology,\n",
        "                         min_homology=min_homology,\n",
        "                         fixed_errors=fixed_errors\n",
        "                         )"
      ],
      "metadata": {
        "id": "bOqz3JYwCqy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save output as json file (and print it out to console)\n",
        "\n",
        "output_file_name='json_output.json'\n",
        "\n",
        "with open(output_file_name, 'w') as outfile:\n",
        "    json.dump(results_dictionary, outfile)\n",
        "    \n",
        "\n",
        "json_object = json.dumps(results_dictionary, indent = 6) \n",
        "print(json_object)"
      ],
      "metadata": {
        "id": "68iV6RItIye5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}